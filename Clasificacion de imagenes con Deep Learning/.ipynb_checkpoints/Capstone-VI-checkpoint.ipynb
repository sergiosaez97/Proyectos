{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRu78-Qg3Nrs"
   },
   "source": [
    "<img src=\"http://www.cidaen.es/assets/img/mCIDaeNnb.png\" alt=\"Logo CiDAEN\" align=\"right\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "<h2><font color=\"#00586D\" size=4>Capstone VI</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#00586D\" size=5>Análisis de un problema de clasificación con deep learning</font></h1>\n",
    "<br><br>\n",
    "\n",
    "<div align=\"right\">\n",
    "<font color=\"#00586D\" size=3>Fernando Rubio, Daniel González</font><br>\n",
    "<font color=\"#00586D\" size=3>Máster en Ciencia de Datos e Ingeniería de Datos en la Nube</font><br>\n",
    "<font color=\"#00586D\" size=3>Universidad de Castilla-La Mancha</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "107M0_283Nrw"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.metrics as confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras as ak"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wjRnhBt6YwXu"
   },
   "source": [
    "**Nota**: en este notebook es esencial utilizar la GPU para entrenar nuestras redes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#00586D\" size=5>Índice</font></h2>\n",
    "\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Dataset](#section2)\n",
    "* [3. Preprocesamiento de datos](#section3)\n",
    "* [4. Ejemplo](#section4)\n",
    "* [5. Creación de un modelo desde cero](#section5)\n",
    "* [6. Ajuste de hiperparámetros](#section6)\n",
    "* [7. Modelos pre-entrenados](#section7)\n",
    "* [8. Data augmentation](#section8)\n",
    "* [9. Autokeras](#section9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeRqW7zg3Ntb"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"section1\"></a> \n",
    "## <font color=\"#00586D\"> 1. Introducción</font>\n",
    "<br>\n",
    "\n",
    "El objetivo del Capstone es **simular un análisis completo de un problema de clasificación de imágenes usando Deep Learning**.\n",
    "\n",
    "El análisis está compuesto de una serie de pasos que iremos viendo detenidamente uno por uno, que os puede servir de guía para seguir a la hora de resolver un problema con Deep Learning. Los **pasos** que vamos a seguir son los siguientes:\n",
    "\n",
    "1. **Dataset**: Descarga y previsualización de los datos.\n",
    "2. **Preprocesamiento de los datos**: prepararemos las imágenes para que puedan ser entrenadas.\n",
    "3. **Modelo desde cero**: Creación de una red neuronal desde cero.\n",
    "4. **Ajuste de hiperparámetros**: Mejora del modelo anterior mediante el ajuste de hiperparámetros.\n",
    "5. **Modelos pre-entrenados (fine-tunning)**: Uso de técnicas de *Finetunning* sobre un modelo pre-entrenado.\n",
    "6. **Data augmentation (Opcional)**: Uso de *data augmentation* en el dataset.\n",
    "7. **Conclusión**: se deberá sacar unas conclusiones a partir de los resultados obtenidos, decidiendo cual de los modelos entrenados podríamos desplegar en producción para usarlo.\n",
    "\n",
    "Los puntos a completar son del 3 al 7, en **cada punto se detalla exactamente qué se tiene que hacer**, es decir, habrá bloques de código en blanco y se detallará las arquitectura de las redes y la configuración de los entrenamientos, por lo que las redes a crear serán las indicadas en cada paso.\n",
    "\n",
    "Al final de cada paso habrá que comentar los resultados obtendos en los entrenamientos, sacando **conclusiones de los experimentos** que vamos a llevar acabo, justificando y midiendo el rendimiento de los modelos obtenidos según las técnicas que utilicemos. La evaluación de los modelos se realizará en terminos de tasa de aciertos y la matriz de confusión de las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtHWRQ4W-ndt"
   },
   "source": [
    "_**Nota**: ejecuta el siguiente código para montar tu Drive y no perder los datos que vayamos a descargar. Además se hará un `cd` hacia el drive para guardar ahí todos los datos generados y descargados_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8-KqkVA_FHT"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a85MYnk_Hsh"
   },
   "outputs": [],
   "source": [
    "cd drive/MyDrive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEqlJukkJIjQ"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"section2\"></a> \n",
    "## <font color=\"#00586D\"> 2. Dataset</font>\n",
    "<br>\n",
    "El dataset utilizado está compuesto por imágenes de distintas razas de perro. El dataset contiene 12.891 imágenes con 74 razas, por lo tanto, el objetivo será crear y entrenar un módelo que clasifique la raza de un perro a partir de una imagen. Para descargar el dataset ejecuta la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgi7ZaCHU-wl",
    "outputId": "f1896dee-5afc-42b8-e089-2e16a832fa1c"
   },
   "outputs": [],
   "source": [
    "!wget 'https://pruebasaluuclm-my.sharepoint.com/:u:/g/personal/fernando_rubio_uclm_es/ESpljekZA9dAgxsfc3qIDvEBMT76g8rPDOpMwgDwHe0BKw?download=1'\n",
    "!mv 'ESpljekZA9dAgxsfc3qIDvEBMT76g8rPDOpMwgDwHe0BKw?download=1' dog-images.zip\n",
    "!unzip -q dog-images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TL1-XBUMVFcR"
   },
   "source": [
    "Se descargará un archivo `dog-images.zip` que se descomprimirá automáticamente creando la carpeta `dog-dataset` que contiene el dataset completo. La estructura de los ficheros descargados sera:\n",
    "\n",
    "```\n",
    "--> dog-images.zip\n",
    "--> dog-dataset/\n",
    "-->    test.csv\n",
    "-->    train.csv\n",
    "-->    valid.csv\n",
    "-->    dog-images/\n",
    "-->        Afghan_hound/\n",
    "-->        African_hunting_dog/\n",
    "-->        ...\n",
    "```\n",
    "\n",
    "\n",
    "En el interior de la carpeta `dog-dataset` se encuentrarn 3 ficheros *CSVs* y otra carpeta (`dog-images`):\n",
    "\n",
    "* Carpeta `dog-images`: contiene todas las imágenes del dataset. Las imágenes están distribuidas por carpetas según las disintas razas (74 carpetas en total). El nombre de cada carpeta corresponde con la raza.\n",
    "* `train.csv`: conjunto de datos para el entrenamiento, 8.992 imágenes. El fichero está en formato *CSV* y cada fila se corresponde con una imagen distinta. El *CSV* tiene 2 columnas, la columna *label* que corresponde a la clase (raza) y la columna *path* que correponde con la ruta donde está cada imagen en la carpeta `dog-images`.\n",
    "* `valid.csv`: conjunto de datos para la validación, 1.894 imágenes. Mismo formato que `train.csv`.\n",
    "* `test.csv`: conjunto de datos para el test, 2.005 imágenes. Mismo formato que `train.csv`.\n",
    "\n",
    "A continuación se muestran varias imágenes del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5MoC7CQVVHLJ",
    "outputId": "fe69a239-ef24-4de9-b519-fbf4df1fac82"
   },
   "outputs": [],
   "source": [
    "def show_images(img_paths):\n",
    "    fig=plt.figure(figsize=(20, 20))\n",
    "    index = np.random.randint(len(img_paths), size=100)\n",
    "    for i in range(100):\n",
    "        fig.add_subplot(10, 10, i+1)\n",
    "        plt.axis('off')\n",
    "        img = Image.open(img_paths[index[i]])\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "files = [f for f in glob.glob(\"dog-dataset/dog-images/**/*.jpg\", recursive=True)]\n",
    "show_images(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdwN0uJWtwJ"
   },
   "source": [
    "Podemos obserar las siguientes características que pueden complicar el problema:\n",
    "\n",
    "- Las imágenes son de **diferentes tamaños**.\n",
    "- Hay **diferentes objetos en las imágenes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAeg_T6gFpYz"
   },
   "source": [
    "Vamos a crear un lista (`classes`) con el nombre de las razas de los perros que serán las clases en las que clasificarán los modelos que creemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XeRjtqCFVVes",
    "outputId": "e31cdb80-9ca0-4368-ffda-2696da9803a7"
   },
   "outputs": [],
   "source": [
    "classes = [f.split('/')[-1] for f in glob.glob(\"dog-dataset/dog-images/**\")]\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wg6CgScMGSeL"
   },
   "source": [
    "Vamos a mostrar una imagen aleatoria por cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "id": "w6FLumukX7sv",
    "outputId": "0a5da109-34a7-49d8-9aad-bbea064f81bc"
   },
   "outputs": [],
   "source": [
    "img_per_class = {}\n",
    "\n",
    "for c in classes:\n",
    "   files = [f for f in glob.glob(f\"dog-dataset/dog-images/{c}/**.jpg\")]\n",
    "   index = np.random.randint(len(files))\n",
    "   img_per_class[c] = files[index]\n",
    "\n",
    "fig=plt.figure(figsize=(20, 20))\n",
    "for i, (k, v) in enumerate(img_per_class.items()):\n",
    "    fig.add_subplot(10, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    img = Image.open(v)\n",
    "    plt.title(k);\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Izvn73SxvIEh"
   },
   "source": [
    "Veamos si las clases están valanceadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "DccBK3GTsj-R",
    "outputId": "e963209c-eb03-4dd8-ac09-a95bca74721d"
   },
   "outputs": [],
   "source": [
    "targets = [len([f for f in glob.glob(f\"dog-dataset/dog-images/{c}/**.jpg\")]) for c in classes]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(classes,targets)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c8orv-nzZnY"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"section3\"></a> \n",
    "## <font color=\"#00586D\"> 3. Preprocesamiento de datos</font>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x28FpHVFHPqa"
   },
   "source": [
    "En esta sección vamos a cargar los datos creando los dataset para el conjunto de training, de validación y de test. En otras prácticas hemos visto como cargar con `tf.keras.utils.Sequence` y `tf.data.Dataset` batches de imágenes. En este caso, nos vamos a centrar en el segundo, ya que es más eficiente, sobre todo en Colab, como comentamos en la sección de Carga de datos masiva.\n",
    "\n",
    "En este Capstone os vamos a dar una serie de funciones que permiten ejecutar los experimentos de forma más rápida para que no os tengáis que preocupar por la configuración de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cl0f9eR_Z5Nw"
   },
   "outputs": [],
   "source": [
    "def read_image(image_path, label):\n",
    "    \"\"\"\n",
    "      Cargamos una imagen usando su ruta (path), la convertimos en tensor y la normalizamos\n",
    "    \"\"\"\n",
    "    contents = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(contents, channels=3)\n",
    "    img = tf.cast(img, tf.float64)\n",
    "    img /= 255.0\n",
    "    return img, label\n",
    "\n",
    "def resize_image(img, label, target_size):\n",
    "    \"\"\"\n",
    "      Redimensionamos una imagen\n",
    "    \"\"\"\n",
    "    resized_img = tf.image.resize(img, target_size)\n",
    "    return resized_img, label\n",
    "\n",
    "def get_dataset(image_paths, image_labels, target_size, batch_size, prep_func=None):\n",
    "    \"\"\"\n",
    "      - Generamos un objeto tf.data.Dataset para optimizar el entrenamiento desde los \n",
    "        paths de las imagenes\n",
    "      - Aplicamos las funciones read_image y resize_image a las imagenes\n",
    "      - Podemos usar una función prep_func si queremos hacer fine-tunning\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "    dataset = dataset.map(read_image)\n",
    "    dataset = dataset.map(lambda x, y: resize_image(x, y, target_size))  \n",
    "\n",
    "    if prep_func != None:\n",
    "        dataset = dataset.map(lambda x, y: (x*255.0, y))\n",
    "        dataset = dataset.map(lambda x, y: (prep_func(x), y))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tewvEzbDfK-t"
   },
   "source": [
    "Con estas funciones, podemos crear unos `tf.data.Dataset` que son óptimos a la hora de leer imágenes en memoria y ejecutar los batches y la forma de crearlos y ejecutarlos es la siguiente: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "age_4QZ2fbUU"
   },
   "source": [
    "```python\n",
    "# definimos el img_size objetivo y el batch_size\n",
    "img_size = (224,224,3)\n",
    "batch_size = 32\n",
    "\n",
    "# esta funcion obtiene la base de datos, e incluso podemos pasarle una preprocessing function\n",
    "train_dataset = get_dataset(images_train_paths, labels_train, img_size[0:-1], batch_size)\n",
    "\n",
    "# ya solo nos queda llamar a fit con la base de datos\n",
    "model.fit(train_dataset, epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMs9c_LDgJpM"
   },
   "source": [
    "Así es como deberemos llamar al método en celdas sucesivas cuando queramos entrenar nuestras redes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mk5gGDfXFKNg"
   },
   "source": [
    "Aunque tenemos los csv con los conjuntos de `train`, `valid` y `test`, vamos generar las particiones nosotros mismos para ver cómo se hace y para asegurarnos que lo hacemos de forma correcta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkWgOSotkrCc"
   },
   "outputs": [],
   "source": [
    "num_to_label = {i: c for i, c in enumerate(classes)}\n",
    "label_to_num = {c: i for i, c in enumerate(classes)}\n",
    "image_paths = np.array([f for f in glob.glob(\"dog-dataset/dog-images/**/*.jpg\", recursive=True)])\n",
    "image_labels =  np.array([label_to_num[f.split('/')[-2]] for f in glob.glob(\"dog-dataset/dog-images/**/*.jpg\", recursive=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otcO1IUmklzx",
    "outputId": "20b8d311-7f12-42c4-c795-e0c0a02ac5d6"
   },
   "outputs": [],
   "source": [
    "shuffler = np.random.permutation(len(image_paths))\n",
    "image_paths = image_paths[shuffler]\n",
    "image_labels = image_labels[shuffler]\n",
    "\n",
    "# Train/valid/test split\n",
    "x_train_valid, x_test, y_train_valid, y_test = train_test_split(image_paths, image_labels, test_size=0.1, random_state=1234, stratify=image_labels)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_valid, y_train_valid, test_size=0.2, random_state=5678, stratify=y_train_valid)\n",
    "\n",
    "print(\"Train: \", x_train.shape)\n",
    "print(\"Valid: \", x_valid.shape)\n",
    "print(\"Test: \", x_test.shape)\n",
    "\n",
    "del x_train_valid, y_train_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnatR46IEbeF"
   },
   "source": [
    "Una vez tenemos listas las particiones, ya solo tenemos que crear los datasets con las funciones proporcionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZNA_CcTyObd"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"section4\"></a> \n",
    "## <font color=\"#00586D\"> 4. Experimento ejemplo</font>\n",
    "<br>\n",
    "\n",
    "Aquí os mostramos un ejemplo de experimento y evaluación de un modelo. Podéis basaros en este para los modelos que tenéis que crear vosotros. Además de las gráficas de train y validación, hay una celda que muestra la matriz de confusión de la clase y que deberéis utillizar en los ejercicios.\n",
    "\n",
    "### <font color=\"#00586D\"> Arquitectura y configuración de la red</font>\n",
    "\n",
    "La arquitectura de la red debe ser siguiente:\n",
    "* Tamaño de entrada será `(100, 120, 3)`.\n",
    "* Capa *Fully connected* con 1 neurona con activación *ReLU*.\n",
    "* Capa de salida con *softmax*.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "* Función de perdida: `categorical_crossentropy`\n",
    "* Optimizador: `Adam`\n",
    "* Learning rate: 0,001\n",
    "* Epochs: 2\n",
    "* Tamaño del batch: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OI77LtoYy1Sv"
   },
   "outputs": [],
   "source": [
    "# Cargamos datos con las funciones de generación de dataset\n",
    "img_size = (100,120,3)\n",
    "train_dataset = get_dataset(x_train, y_train, img_size[:-1], 128)\n",
    "valid_dataset = get_dataset(x_valid, y_valid, img_size[:-1], 128)\n",
    "test_dataset = get_dataset(x_test, y_test, img_size[:-1], 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXe88dXjy1Sz"
   },
   "outputs": [],
   "source": [
    "# Creamos nuestra red\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(img_size),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(1, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(len(classes), activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuPBBmfwy1S0"
   },
   "outputs": [],
   "source": [
    "# Configuramos entrenamiento\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATJg4CmQy1S1"
   },
   "outputs": [],
   "source": [
    "# Entrenamos\n",
    "history = model.fit(train_dataset, epochs=2, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDx7ffV1y1S1"
   },
   "outputs": [],
   "source": [
    "# Evaluamos con el conjunto de test\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqA0p_Kxy1S2"
   },
   "outputs": [],
   "source": [
    "# Visualizamos la evolución de los epochs\n",
    "fig=plt.figure(figsize=(60, 40))\n",
    "\n",
    "# error\n",
    "fig.add_subplot(10, 10, 2)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "# precision\n",
    "fig.add_subplot(10, 10, 1)\n",
    "plt.plot(history.history['accuracy'], label='acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkSjv49zy1S2"
   },
   "outputs": [],
   "source": [
    "# Visualizamos la matriz de confusion\n",
    "predictions = model.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true= y_test\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "df_cm=pd.DataFrame(confusion_matrix, index = [i for  i in classes], columns = [i for i in classes])\n",
    "plt.figure(figsize = (20,20))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PB948lkZeEI"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"section5\"></a> \n",
    "## <font color=\"#00586D\"> 5. Creación de un modelo desde cero</font>\n",
    "<br>\n",
    "\n",
    "\n",
    "En esta sección se diseñará y entrenará una red convolucional siguiendo una estructura de tipo *VGG16* como las que vimos en clase. Una vez entrenada la red, tendrás que evaluar el resultado.\n",
    "\n",
    "### <font color=\"#00586D\"> Arquitectura y configuración de la red</font>\n",
    "\n",
    "La arquitectura de la red debe ser siguiente:\n",
    "* Tamaño de entrada será `(100, 120, 3)`.\n",
    "* Capa convolucional con 32 kernels de tamaño 5x5 con activación *ReLU*.\n",
    "* Capa *Max Pooling* con reducción de 2.\n",
    "* Capa convolucional con 64 kernels de tamaño 5x5 con activación *ReLU*.\n",
    "* Capa *Max Pooling* con reducción de 2.\n",
    "* Capa *Fully connected* con 1024 neuronas con activación *ReLU*.\n",
    "* Capa de salida con *softmax*.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "* Función de perdida: `categorical_crossentropy`\n",
    "* Optimizador: `Adam`\n",
    "* Learning rate: 0,001\n",
    "* Epochs: 10\n",
    "* Tamaño del batch: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QI96ttiBUJOj"
   },
   "outputs": [],
   "source": [
    "# Cargamos datos con las funciones de generación de dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdNwVgPuNrEu"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR:\n",
    "#   - Crear la red\n",
    "#   - Entrena la red\n",
    "#   - Evalúa la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtén las gráficas de evaluación y la matriz de confusión y  extrae conclusiones de estos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`Completar aquí`\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xExnes-uqob1"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"section6\"></a> \n",
    "## <font color=\"#00586D\"> 6. Ajuste de hiperparámetros</font>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "En esta sección vamos a intentar mejorar la red anterior con capas `Dropout` y cambiando los hiperparámetros.\n",
    "\n",
    "La arquitectura de la red es la siguiente:\n",
    "\n",
    "* Tamaño de entrada será `(100, 120, 3)`.\n",
    "* Capa convolucional con 32 kernels de tamaño 5x5 con activación *ReLU*.\n",
    "* Capa *Max Pooling* con reducción de 2.\n",
    "* Capa *Dropout* con valor 0.5.\n",
    "* Capa convolucional con 64 kernels de tamaño 5x5 con activación *ReLU*.\n",
    "* Capa *Max Pooling* con reducción de 2.\n",
    "* Capa convolucional con 64 kernels de tamaño 5x5 con activación *ReLU*.\n",
    "* Capa *Max Pooling* con reducción de 2.\n",
    "* Capa *Dropout* con valor 0.5.\n",
    "* Capa *Fully connected* con 1024 neuronas con activación *ReLU*.\n",
    "* Capa *Dropout* con valor 0.2.\n",
    "* Capa de salida con *softmax*.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "* Función de perdida: `categorical_crossentropy`\n",
    "* Optimizador: `Adam`\n",
    "* Learning rate: 0,001\n",
    "* Epochs: 10\n",
    "* Tamaño del batch: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p89ZdFbkhHPH"
   },
   "outputs": [],
   "source": [
    "# Cargamos datos con las funciones de generación de dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw6mXN5sZ-Cz"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR:\n",
    "#   - Crear la red\n",
    "#   - Entrena la red\n",
    "#   - Evalúa la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtén las gráficas de evaluación y la matriz de confusión y  extrae conclusiones de estos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`Completar aquí`\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QQtE0ODY2dF"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"section7\"></a> \n",
    "## <font color=\"#00586D\"> 7. Modelos pre-entrenados (fine-tunning)</font>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "En esta sección tendréis que utilizar los conocimientos sobre los modelos pre-entrenados y _fine-tunning_, donde tendréis que adaptar una red pre-entrenada a nuestro problema. El modelo pre-entreando que tendréis que usar es _Inception_, cuya versión 3 es de las más utilizadas en _Fine-tuning_ por sus buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqtn0bhCEJ0s"
   },
   "source": [
    "### <font color=\"#00586D\"> Inception</font>\n",
    "\n",
    "\n",
    "La configuración de la red a cargar es la siguiente:\n",
    "\n",
    "* Tamaño de entrada será `(299, 299, 3)`.\n",
    "* Elegiremos la configuración `include_top = false` y el `pooling = 'avg'`\n",
    "* Añadiremos una capa de _Dropout_ de 0.5\n",
    "* Capa de salida con *softmax*.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "* Función de perdida: `categorical_crossentropy`\n",
    "* Optimizador: `Adam`\n",
    "* Epochs: 10\n",
    "* Tamaño del batch: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wpzyRgYU6mS"
   },
   "outputs": [],
   "source": [
    "# Cargamos datos con las funciones de generación de dataset\n",
    "# esta vez usams la fucnion de preprocesamiento de inception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwDJQB90Z3sO"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR:\n",
    "#   - Crear la red\n",
    "#   - Entrena la red\n",
    "#   - Evalúa la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtén las gráficas de evaluación y la matriz de confusión y  extrae conclusiones de estos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`Completar aquí`\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmAg6-YiXATB"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"section8\"></a> \n",
    "## <font color=\"#00586D\"> 8. Data augmentation</font>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "En este apartado se deberán aplicar algunas de las funciones de preprocesamiento vistas en la clase de _data augmentation_. Nos centraremos en *data augmentation* estocástico sobre la red obtenida en el apartado de modelos desde 0 y tratar de mejorar el rendimiento. Vamos a utilizar una o varias de las siguientes modificaciones:\n",
    "\n",
    "  *    Flip horizontal\n",
    "  *    Flip vertical\n",
    "  *    Contraste\n",
    "\n",
    "La arquitectura de la red debe ser siguiente:\n",
    "* Tamaño de entrada será `(100, 120, 3)`.\n",
    "* Capa convolucional con 32 kernels de tamaño 5x5 con activación *ReLU*.\n",
    "* Capa *Max Pooling* con reducción de 2.\n",
    "* Capa convolucional con 64 kernels de tamaño 5x5 con activación *ReLU*.\n",
    "* Capa *Max Pooling* con reducción de 2.\n",
    "* Capa *Fully connected* con 1024 neuronas con activación *ReLU*.\n",
    "* Capa de salida con *softmax*.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "* Función de perdida: `categorical_crossentropy`\n",
    "* Optimizador: `Adam`\n",
    "* Learning rate: 0,001\n",
    "* Epochs: 10\n",
    "* Tamaño del batch: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhpu12f3XATC"
   },
   "outputs": [],
   "source": [
    "# Cargamos datos con las funciones de generación de dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-qmDuAYXATC"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR:\n",
    "#   - Crear la red\n",
    "#   - Entrena la red\n",
    "#   - Evalúa la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtén las gráficas de evaluación y la matriz de confusión y  extrae conclusiones de estos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`Completar aquí`\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd6WF4zScRlY"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"section9\"></a> \n",
    "## <font color=\"#00586D\"> AutoKeras (opcional) </font>\n",
    "<br>\n",
    "\n",
    "\n",
    "En este experimentos vamos a utilizar AutoKeras para realizar el entrenamiento. Nos centraremos en utilizar el bloque `ImageClassifier` a alto nivel, con tan solo un `max_trials` de 1 ya que será un experimento muy costoso computacionalmente.\n",
    "\n",
    "La arquitectura de la red debe ser siguiente:\n",
    "* Tamaño de entrada será `(100, 120, 3)`.\n",
    "* Bloque `ImageClassifier` con la siguiente configuración:\n",
    "  - `max_trials` de 1\n",
    "  - En `metrics` incluye el `accuracy`\n",
    "  - `overwrite` a `True`\n",
    "\n",
    "  En este tipo de bloque puedes pasarle al parámetro `x` un `tf.data.Dataset` al igual que al parámetros `validation_data`.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "* Epochs: 10\n",
    "* Callbacks: usa `EarlyStopping` con un `patience` de 2 para terminar antes el entrenamiento si el modelo deja de aprender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ypm40sCcV9tI"
   },
   "outputs": [],
   "source": [
    "# Cargamos datos con las funciones de generación de dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ci6Ld8cwc-74"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR:\n",
    "#   - Crear la red\n",
    "#   - Entrena la red\n",
    "#   - Evalúa la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtén las gráficas de evaluación y la matriz de confusión y  extrae conclusiones de estos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`Completar aquí`\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bzyn_HfdeBs"
   },
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"sectionopt\"></a> \n",
    "## <font color=\"#00586D\"> Conclusión</font>\n",
    "<br>\n",
    "\n",
    "\n",
    "Una vez realizado todos los experimentos anteriores, ¿qué modelo elegirías para desplegar en producción? ¿Por qué? \n",
    "\n",
    "Explica en breves palabras qué modelo eligirías para desplegar en producción y porqué. Compara cada experimento y extráe tus propias conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`Completar aquí`\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F1Fm_YP1hpK"
   },
   "source": [
    "<div style=\"text-align: center; font-size: 24px;\">\n",
    "    <img src=\"https://drive.google.com/uc?id=1xHx0M9NUXi4YcDyi1BwuUE6y0TK0kHfs\">\n",
    "</div>\n",
    "\n",
    "####  ¡Si has llegado hasta aquí deberías estar super orgullos@!  Ya puedes relajar tus neuronas, les has dado mucho trabajo\n",
    "\n",
    "\n",
    "\n",
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=5 color=\"#00586D\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"right\">\n",
    "<a href=\"#indice\"><font size=6 color=\"#00586D\"><i class=\"fa fa-coffee\" aria-hidden=\"true\"></i></font></a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mc2_m6_capstone.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
